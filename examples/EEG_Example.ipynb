{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `mltsp` Tutorial: Epilepsy Detection Using EEG Data\n",
    "\n",
    "In this example we'll use the [`mltsp`](http://github.com/mltsp/mltsp/) library to compare various techniques for epilepsy detection using a classic EEG time series dataset from [Andrzejak et al.](http://www.meb.uni-bonn.de/epileptologie/science/physik/eegdata.html). The raw data are separated into five classes: Z, O, N, F, and S; we will consider a three-class classification problem of distinguishing normal (Z, O), interictal (N, F), and ictal (S) signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load the data and inspect a representative time series from each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettnaul/anaconda/envs/mltsp3k/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n",
      "WARNING:mltsp.datasets.andrzejak:Downloading data from http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/mltsp/mltsp/datasets/andrzejak.py\u001b[0m in \u001b[0;36mfetch_andrzejak\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded data from cached archive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/anaconda/envs/mltsp3k/lib/python3.5/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;31m# We are careful to open the file handle early and keep it open to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/brettnaul/.local/mltsp/andrzejak/andrzejak.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5ab58e34ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmltsp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0meeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_andrzejak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'U16'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  allocate memory for longer class names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/mltsp/mltsp/datasets/andrzejak.py\u001b[0m in \u001b[0;36mfetch_andrzejak\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded data from cached archive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#  missing or incompatible cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_andrzejak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/mltsp/mltsp/datasets/andrzejak.py\u001b[0m in \u001b[0;36mdownload_andrzejak\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     ts_paths = dsutil.download_and_extract_archives(data_dir, BASE_URL,\n\u001b[0;32m---> 57\u001b[0;31m                                                       ZIP_FILES, MD5SUMS)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Reformat time series files and add to `andrzejak.tar.gz` archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/mltsp/mltsp/datasets/util.py\u001b[0m in \u001b[0;36mdownload_and_extract_archives\u001b[0;34m(data_dir, base_url, filenames, md5sums, remove_archive)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmd5sums\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_md5sum_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmd5sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/anaconda/envs/mltsp3k/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/anaconda/envs/mltsp3k/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/anaconda/envs/mltsp3k/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()\n",
    "\n",
    "from mltsp import datasets\n",
    "\n",
    "eeg = datasets.fetch_andrzejak()\n",
    "eeg.classes = eeg.classes.astype('U16') #  allocate memory for longer class names\n",
    "eeg.classes[np.logical_or(eeg.classes=='Z', eeg.classes=='O')] = 'Normal'\n",
    "eeg.classes[np.logical_or(eeg.classes=='N', eeg.classes=='F')] = 'Interictal'\n",
    "eeg.classes[eeg.classes=='S'] = 'Ictal'\n",
    "fig, ax = plt.subplots(1, len(np.unique(eeg.classes)), sharey=True)\n",
    "for label, subplot in zip(np.unique(eeg.classes), ax):\n",
    "    i = np.where(eeg.classes == label)[0][0]\n",
    "    subplot.plot(eeg.times[i], eeg.measurements[i])\n",
    "    subplot.set(xlabel='time (s)', ylabel='signal', title=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization\n",
    "Once the data is loaded, we can generate features for each time series using the [`mltsp.featurize`](https://mltsp.readthedocs.org/en/latest/api/mltsp.featurize.html) module, which will then be used to train machine learning models. Here we've chosen a few generic features that do not have any special biological significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mltsp import featurize\n",
    "\n",
    "features_to_use = ['amplitude',\n",
    "                   'percent_beyond_1_std',\n",
    "                   'maximum',\n",
    "                   'max_slope',\n",
    "                   'median',\n",
    "                   'median_absolute_deviation',\n",
    "                   'percent_close_to_median',\n",
    "                   'minimum',\n",
    "                   'skew',\n",
    "                   'std',\n",
    "                   'weighted_average']\n",
    "fset_mltsp = featurize.featurize_time_series(eeg.times, eeg.measurements,\n",
    "                                             None, features_to_use,\n",
    "                                             eeg.classes)\n",
    "\n",
    "print(fset_mltsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `featurize_time_series` is an `xray.Dataset` which contains all the feature information needed to train a machine learning model: feature values are stored as data variables, and the time series index/class label are stored as coordinates (the `channel` coordinate will be used later for multi-channel data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom feature functions not built into `mltsp` may be passed in using the `custom_functions` keyword, either as a dictionary `{feature_name: function}`, or as a [dask graph](http://dask.pydata.org/en/latest/custom-graphs.html). Functions should take three arrays `times, measurements, errors` as inputs; details can be found in the `mltsp.featurize` [documentation](https://mltsp.readthedocs.org/en/latest/api/mltsp.featurize.html#mltsp.featurize.featurize_time_series). Here we'll compute five standard features for EEG analysis provided by [Guo et al. (2012)](http://linkinghub.elsevier.com/retrieve/pii/S0957417411003253)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "guo_features = {\n",
    "    'mean': lambda t, m, e: np.mean(m),\n",
    "    'std': lambda t, m, e: np.std(m),\n",
    "    'mean2': lambda t, m, e: np.mean(m ** 2),\n",
    "    'abs_diffs': lambda t, m, e: np.sum(np.abs(np.diff(m))),\n",
    "    'skew': lambda t, m, e: scipy.stats.skew(m)\n",
    "}\n",
    "fset_guo = featurize.featurize_time_series(eeg.times, eeg.measurements, None, \n",
    "                                           guo_features.keys(), eeg.classes, \n",
    "                                           custom_functions=guo_features)\n",
    "print(fset_guo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EEG time series considered here consist of univariate signal measurements along a uniform time grid. But `featurize_time_series` also accepts multi-channel data; to demonstrate this, we will decompose each signal into five frequency bands using a discrete wavelet transform as suggested by [Subasi (2005)](http://www.sciencedirect.com/science/article/pii/S0957417404001745), and then featurize each band separately using the five functions from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "n_channels = 5\n",
    "eeg.dwts = [pywt.wavedec(m, pywt.Wavelet('db1'), level=n_channels-1) for m in eeg.measurements]\n",
    "fset_dwt = featurize.featurize_time_series(None, eeg.dwts, None, \n",
    "                                           guo_features.keys(), eeg.classes, \n",
    "                                           custom_functions=guo_features)\n",
    "print(fset_dwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output featureset has the same form as before, except now the `channel` coordinate is used to index the features by the corresponding frequency band. The functions in `mltsp.build_model` and `mltsp.predict` all accept featuresets from single- or multi-channel data, so no additional steps are required to train models or make predictions for multichannel featuresets using the `mltsp` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Model building in `mltsp` is handled by the `build_model_from_featureset` function in the `mltsp.build_model` submodule. The featureset output by `featurize_time_series` contains both the feature and target information needed to train a model; `build_model_from_featureset` is simply a wrapper that calls the `fit` method of a given `scikit-learn` model with the appropriate inputs. In the case of multichannel features, it also handles reshaping the featureset into a (rectangular) form that is compatible with `scikit-learn`.\n",
    "\n",
    "For this example, we'll test a random forest classifier for the built-in `mltsp` features, and a 3-nearest neighbors classifier for the others, as suggested by [Guo et al. (2012)](http://linkinghub.elsevier.com/retrieve/pii/S0957417411003253)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mltsp.build_model import build_model_from_featureset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, test = train_test_split(np.arange(len(eeg.classes)))\n",
    "\n",
    "model_mltsp = build_model_from_featureset(fset_mltsp.isel(name=train), \n",
    "                                          RandomForestClassifier(n_estimators=1000,\n",
    "                                                                 max_features='auto',\n",
    "                                                                 random_state=0))\n",
    "model_guo = build_model_from_featureset(fset_guo.isel(name=train), \n",
    "                                        KNeighborsClassifier(n_neighbors=3))\n",
    "model_dwt = build_model_from_featureset(fset_dwt.isel(name=train), \n",
    "                                        KNeighborsClassifier(n_neighbors=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Making predictions for new time series based on these models follows the same pattern: first the time series are featurized using `featurize_time_series`, and then predictions are made based on these features using `mltsp.predict.model_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mltsp.predict import model_predictions\n",
    "\n",
    "preds_mltsp = model_predictions(fset_mltsp, model_mltsp, return_probs=False)\n",
    "preds_guo = model_predictions(fset_guo, model_guo, return_probs=False)\n",
    "preds_dwt = model_predictions(fset_dwt, model_dwt, return_probs=False)\n",
    "\n",
    "print(\"Built-in MLTSP features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n",
    "        np.mean(preds_mltsp[train] == eeg.classes[train]), \n",
    "        np.mean(preds_mltsp[test] == eeg.classes[test])))\n",
    "print(\"Guo et al. features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n",
    "        np.mean(preds_guo[train] == eeg.classes[train]), \n",
    "        np.mean(preds_guo[test] == eeg.classes[test])))\n",
    "print(\"Wavelet transform features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n",
    "        np.mean(preds_dwt[train] == eeg.classes[train]), \n",
    "        np.mean(preds_dwt[test] == eeg.classes[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow presented here is intentionally simplistic and omits many important steps such as feature selection, model parameter selection, etc. Since we make use of standard `scikit-learn` models, additional steps can be incorporated in exactly the way as for any other (non-time domain) machine learning problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
