#!/usr/bin/python

from __future__ import print_function
from parse import parse
import sys
import os
import json
import uuid
import io
import tarfile
import shutil
import numpy as np
from importlib import import_module
from .cfg import config
from . import util
from os.path import join as pjoin

class MissingRequiredParameterError(Exception):

    """Required parameter is not provided in feature function call."""

    def __init__(self, value):
        self.value = value

    def __str__(self):
        return str(self.value)


class MissingRequiredReturnKeyError(Exception):

    """Required return value is not provided in feature definition."""

    def __init__(self, value):
        self.value = value

    def __str__(self):
        return str(self.value)


class myFeature(object):

    """Decorator for custom-defined time series feature(s) function.

    Applies function wrapper that ensures required parameters and
    return values are present before executing, raising an exception if
    not.

    Attributes
    ----------
    requires : list
        List of names of features required for decorated function to
        execute.
    provides : list
        List of names of features generated by decorated function.

    """

    def __init__(self, requires, provides):
        """Instantiates object, sets args as attributes.

        Parameters
        ----------
        requires : list
            List of variable names required by the function.
        provides : list
            List of the key names of the returned dictionary - the
            features calculated by a particular function.

        """
        self.requires = requires
        self.provides = provides

    def __call__(self, f):
        """Wrap decorated function.

        Wrap decorated function with a check to ensure that required
        parameters (specified in decorator expression) are provided
        upon function call (raises MissingRequiredParameterError if
        not) and that all features reportedly returned (specified in
        decorator expression) are in fact returned (raises
        MissingRequiredReturnKeyError if not).

        Returns
        -------
        function
            The wrapped function.

        """
        def wrapped_f(*args, **kwargs):
            for required_arg in self.requires:
                if required_arg not in args and required_arg not in kwargs:
                    raise MissingRequiredParameterError(
                        "Required arg %s not provided in function call." %
                        required_arg)
            result_dict = f(*args, **kwargs)
            for provided in self.provides:
                if provided not in result_dict:
                    raise MissingRequiredReturnKeyError(
                        "Key %s not present in function return value." %
                        provided)
            return result_dict
        return wrapped_f


class DummyFile(object):

    """Used as a file object to temporarily redirect/suppress output."""

    def write(self, x):
        pass

    def flush(self):
        pass


def parse_for_req_prov_params(script_fpath):
    """
    """
    with open(script_fpath, "r") as f:
        all_lines = f.readlines()
    fnames_req_prov_dict = {}
    all_required_params = []
    all_provided_params = []
    for i in range(len(all_lines) - 1):
        if "@myFeature" in all_lines[i] and "def " in all_lines[i + 1]:
            reqs_provs_1 = parse(
                "@myFeature(requires={requires}, provides={provides})",
                all_lines[i].strip())
            func_name = parse(
                "def {funcname}({args}):", all_lines[i + 1].strip())
            fnames_req_prov_dict[func_name.named['funcname']] = {
                "requires": eval(reqs_provs_1.named["requires"]),
                "provides": eval(reqs_provs_1.named["provides"])}
            all_required_params = list(set(
                all_required_params +
                list(set(eval(reqs_provs_1.named["requires"])))))
            all_provided_params = list(set(
                all_provided_params +
                list(set(eval(reqs_provs_1.named["provides"])))))
    return (fnames_req_prov_dict, all_required_params, all_provided_params)


def call_custom_functions(features_already_known, all_required_params,
                          all_provided_params, fnames_req_prov_dict,
                          script_fpath):
    """
    """
    # import the custom feature defs
    with open(script_fpath) as f:
        script_dir, script_filename = os.path.split(script_fpath)
        code = compile(f.read(), script_filename, 'exec')

    custom_feature_defs = {}
    exec(code, custom_feature_defs)

    # temporarily redirect stdout:
    save_stdout = sys.stdout
    sys.stdout = DummyFile()

    all_required_params = [x for x in all_required_params
                           if x not in features_already_known]

    params_missing = set(all_required_params) - set(all_provided_params)
    if params_missing:
        raise Exception((
            "Not all of the required parameters are provided by the "
            "functions in this script (required parameter(s) '%s').") %
            params_missing)

    funcs_round_1 = []
    func_queue = []
    funcnames = list(fnames_req_prov_dict.keys())
    i = 0
    func_rounds = {}
    all_extracted_features = {}
    while len(funcnames) > 0:
        func_rounds[str(i)] = []
        for funcname in funcnames:
            reqs_provs_dict = fnames_req_prov_dict[funcname]
            reqs = reqs_provs_dict['requires']
            provs = reqs_provs_dict['provides']
            if len(set(all_required_params) & set(reqs)) > 0:
                func_queue.append(funcname)
            else:
                func_rounds[str(i)].append(funcname)
                all_required_params = [x for x in all_required_params
                                       if x not in provs]
                arguments = {}
                for req in reqs:
                    if req in features_already_known:
                        arguments[req] = features_already_known[req]
                    elif req in all_extracted_features:
                        arguments[req] = all_extracted_features[req]
                func_result = custom_feature_defs[funcname](**arguments)
                all_extracted_features = dict(
                    list(all_extracted_features.items()) +
                    list(func_result.items()))
                funcnames.remove(funcname)
        i += 1
    # revert to original stdout
    sys.stdout = save_stdout
    try:
        os.remove(copied_path)
        os.remove(copied_path.replace('.py', '.pyc'))
    except:
        pass
    return all_extracted_features


def execute_functions_in_order(script_fpath, features_already_known):
    """Generate custom features defined in script_fpath.

    Parses the script (which must have function definitions with
    decorators specifying the required parameters and those which are
    provided by each function) and executes the functions defined in
    that script such that all functions whose outputs are required
    as inputs of other functions are called first, if possible,
    otherwise raises an Exception.

    Parameters
    ----------
    script_fpath : str
        Path to custom feature definitions script.
    features_already_known : dict
        Dictionary providing all time-series data (time ("t"), magnitude
        ("m"), error ("e") as keys) and any meta-features.
        Example:
            {"t": [1, 2, 3], "m": [10.32, 11.41, 11.06],
             "e": [0.2015,0.3134,0.2953], "coords": [22.55,33.01]}

    Returns
    -------
    dict
        Dictionary of all extracted features (key-value pairs are
        feature name and feature value respectively).

    """
    # For when run inside Docker container:
    import sys, os

    fnames_req_prov_dict, all_required_params, all_provided_params = \
        parse_for_req_prov_params(script_fpath)

    all_extracted_features = call_custom_functions(
        features_already_known, all_required_params, all_required_params,
        fnames_req_prov_dict, script_fpath)

    return all_extracted_features



def docker_copy(docker_client, container_id, path, target="."):
    """Copy file from docker container to host machine.

    Parameters
    ----------
    docker_client : docker.Client object
        The connected Docker client.
    container_id : str
        ID of the container to copy from.
    path : str
        Path to the file in the container.
    target : str
        Folder where to put the file.

    """
    response = docker_client.copy(container_id, path)
    buffer = io.BytesIO()
    buffer.write(response.data)
    buffer.seek(0)
    tar = tarfile.open(fileobj=buffer, mode='r|')
    tar.extractall(path=target)


def extract_feats_in_docker_container(container_name, tmp_dir):
    """
    """
    try:
        # Spin up Docker contain and extract custom feats
        # Instantiate Docker client
        client = util.get_docker_client()

        proj_mount_path = config['paths']['project_path']

        # Create container
        cont_id = client.create_container(
            image="mltsp/base",
            command=("python {}/docker_scripts/extract_custom_feats.py "
                     "--tmp_dir={}").format(proj_mount_path, tmp_dir),
            tty=True,
            volumes=[proj_mount_path, tmp_dir])["Id"]

        # Start container
        client.start(cont_id,
                     binds={proj_mount_path: {"bind": proj_mount_path,
                                              "ro": True},
                            tmp_dir: {"bind": tmp_dir,
                                      "ro": True}})

        # Wait for process to complete
        client.wait(cont_id)
        stdout = client.logs(container=cont_id, stdout=True)
        stderr = client.logs(container=cont_id, stderr=True)
        if stderr.strip():
            print("\n\ndocker container stderr:\n\n", stderr.strip(), "\n\n")
        # Copy JSON results data from Docker container to host
        docker_copy(client, cont_id, "/tmp/results_dict.json",
                    target=tmp_dir)

        print("/tmp/results_dict.json copied to host machine.")

        # Load results data
        with open(pjoin(tmp_dir, "results_dict.json"), "r") as f:
            return json.load(f)

    finally:
        # Kill and remove the container
        try:
            client.remove_container(container=cont_id, force=True)
        except UnboundLocalError as e:
            print("Error occurred while running Docker container:")
            print(e)



def docker_extract_features(script_fpath, features_already_known):
    """Extract custom features in a Docker container.

    Spins up a docker container in which custom script
    excecution/feature extraction is done inside. Resulting data are
    copied to host machine and returned as a dict.

    Parameters
    ----------
    script_fpath : str
        Path to script containing custom feature definitions.
    features_already_known : dict
        List of dictionaries containing time series data (t,m,e) and
        any meta-features to be used in generating custom features.
        Defaults to []. NOTE: If omitted, or if "t" or "m" are not
        among contained dict keys, (a) respective element of
        `ts_datafile_paths` or (b) `ts_data` (see below) MUST not
        be None, otherwise raises ValueError.
    ts_data: list of list OR str, optional
        List of either (a) list of lists/tuples each containing t,m(,e)
        for each epoch, or (b) string containing equivalent comma-
        separated lines, each line being separated by a newline
        character ("\n"). Defaults to None. NOTE: If None, either
        `ts_datafile_paths` must not be None or "t" (time) and "m"
        (magnitude/measurement) must be among the keys of
        respective element of `features_already_known` (see
        above), otherwise raisesValueError.

    Returns
    -------
    list of dict
        List of dictionaries of all generated features.

    """
    container_id = str(uuid.uuid4())[:10]
    tmp_dir = tempfile.mkdtemp(prefix='mltsp')

    try:
        shutil.copy(script_fpath, pjoin(tmp_dir, "custom_feature_defs.py"))
        with open(pjoin(tmp_dir, "features_already_known.json"), "w") as f:
            json.dump(features_already_known, f)

        results_dict = extract_feats_in_docker_container(container_id, tmp_dir)
    finally:
        shutil.rmtree(tmp_dir, ignore_errors=True)

    return results_dict


def assemble_test_data():
    """
    """
    fname = pjoin(config['paths']['sample_data_path'],
                         "dotastro_215153.dat")
    t, m, e = np.loadtxt(fname, delimiter=',').T
    features_already_known = {'t': list(t), 'm': list(m), 'e': list(e)}
    return features_already_known


def verify_new_script(script_fpath, docker_container=False):
    """Test custom features script and return generated features.

    Performs test run on custom feature def script with trial time
    series data sets and returns list of dicts containing extracted
    features if successful, otherwise raises an exception.

    Parameters
    ----------
    script_fpath : str
        Path to custom feature definitions script.
    docker_container : bool, optional
        Boolean indicating whether function is being called from within
        a Docker container.

    Returns
    -------
    list of dict
        List of dictionaries of extracted features for each of the trial
        time-series data sets.

    """
    features_already_known = assemble_test_data()
    print(script_fpath, os.path.isfile(script_fpath))

    all_extracted_features = {}
    if config['testing']['no_docker']:
        print("WARNING - generating custom features WITHOUT docker container...")
        all_extracted_features = execute_functions_in_order(
            features_already_known=features_already_known,
            script_fpath=script_fpath)
    elif util.docker_images_available():
        print("Extracting features inside docker container...")
        all_extracted_features = docker_extract_features(
            script_fpath=script_fpath,
            features_already_known=features_already_known)
    else:
        raise Exception("Feature extraction inside Docker images requested, "
                        "but no suitable Docker images available.")
    return all_extracted_features


def list_features_provided(script_fpath):
    """Parses script and returns a list of all features it provides.

    Parses decorator expression in custom feature definitions script,
    returning a list of all feature names generated by the various
    definitions in that script.

    Parameters
    ----------
    script_fpath : str
        Path to custom features definition script.

    Returns
    -------
    list of str
        List of feature names that the script will generate.

    """
    with open(script_fpath, "r") as f:
        all_lines = f.readlines()
    fnames_req_prov_dict = {}
    all_required_params = []
    all_provided_params = []
    for i in range(len(all_lines) - 1):
        if "@myFeature" in all_lines[i] and "def " in all_lines[i + 1]:
            reqs_provs_1 = parse(
                "@myFeature(requires={requires}, provides={provides})",
                all_lines[i].strip())
            func_name = parse(
                "def {funcname}({args}):", all_lines[i + 1].strip())
            fnames_req_prov_dict[func_name.named['funcname']] = {
                "requires": eval(reqs_provs_1.named["requires"]),
                "provides": eval(reqs_provs_1.named["provides"])}
            all_required_params = list(set(
                all_required_params +
                list(set(eval(reqs_provs_1.named["requires"])))))
            all_provided_params = list(set(
                all_provided_params +
                list(set(eval(reqs_provs_1.named["provides"])))))
    return all_provided_params


def generate_custom_features(custom_script_path, t, m, e,
                             features_already_known={}):
    """Generate custom features for provided TS data and script.

    Parameters
    ----------
    t : array_like
        Array containing time values.

    m : array_like
        Array containing data values.

    e : array_like
        Array containing measurement error values.

    custom_script_path : str
        Path to custom features script.

    features_already_known : dict, optional
        Dict containing any meta-features associated with provided time-series
        data. Defaults to {}.

    Returns
    -------
    dict
        Dictionary containing newly-generated features.
    """
    features_already_known['t'] = list(t)
    features_already_known['m'] = list(m)
    features_already_known['e'] = list(e)

    if util.is_running_in_docker():
        all_new_features = execute_functions_in_order(
            features_already_known=features_already_known,
            script_fpath=custom_script_path)
    else:
        if config['testing']['no_docker']:
            print("WARNING - generating custom features WITHOUT docker container...")
            all_new_features = execute_functions_in_order(
                features_already_known=features_already_known,
                script_fpath=custom_script_path)
        elif util.docker_images_available():
            print("Generating custom features inside docker container...")
            all_new_features = docker_extract_features(
                script_fpath=custom_script_path,
                features_already_known=features_already_known)
        else:
            raise Exception("Feature extraction inside Docker images requested, "
                            "but no suitable Docker images available.")

    return all_new_features
