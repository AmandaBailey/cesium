{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'andrzejak/Z.zip' already there; not retrieving.\n",
      "\n",
      "File 'andrzejak/O.zip' already there; not retrieving.\n",
      "\n",
      "File 'andrzejak/N.zip' already there; not retrieving.\n",
      "\n",
      "File 'andrzejak/F.zip' already there; not retrieving.\n",
      "\n",
      "File 'andrzejak/S.zip' already there; not retrieving.\n",
      "\n",
      "Archive:  andrzejak/F.zip\n",
      "\n",
      "Archive:  andrzejak/N.zip\n",
      "\n",
      "Archive:  andrzejak/O.zip\n",
      "\n",
      "Archive:  andrzejak/S.zip\n",
      "\n",
      "Archive:  andrzejak/Z.zip\n",
      "\n",
      "5 archives were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "!mkdir -p andrzejak\n",
    "!wget -nc -P andrzejak http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/{Z,O,N,F,S}.zip\n",
    "!unzip -uL 'andrzejak/*.zip' -d andrzejak/ # convert to lowercase; N.zip files are .TXT\n",
    "filenames = glob.glob('andrzejak/[zfson]*.txt')\n",
    "#values_list = [np.loadtxt(f) for f in filenames]\n",
    "#T_MAX = 23.6\n",
    "#for f in filenames:\n",
    "#    m = np.loadtxt(f)\n",
    "#    t = np.linspace(start=0, stop=T_MAX, num=len(m))\n",
    "#    e = np.repeat(1e-6, len(t))\n",
    "#    np.savetxt(f[:-3] + 'dat', np.vstack((t,m,e)).T, delimiter=',')\n",
    "#with open('andrzejak/test_header.dat', 'w') as header:\n",
    "#    header.write('filename,class\\n')\n",
    "#    for f in filenames:\n",
    "#        short_fname = f.split('/')[1]\n",
    "#        header.write(\"{},{}\\n\".format(short_fname[:-4], short_fname[0]))\n",
    "#!COPYFILE_DISABLE=1 tar czf andrzejak/test_data.tar.gz andrzejak/[zs]*.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "T_MAX = 23.6\n",
    "filenames = glob.glob('andrzejak/[zonsf]*.txt')\n",
    "m_list = [np.loadtxt(f) for f in filenames]\n",
    "#t_list = [np.linspace(start=0, stop=T_MAX, num=len(m)) for m in m_list]\n",
    "#e_list = [np.repeat(1e-5, len(m)) for m in m_list]\n",
    "classes = np.array([f.split('/')[1][0] for f in filenames]) # class == file prefix\n",
    "classes = classes.astype('S16') # space for >1 character class names\n",
    "classes[classes != 'z'] = 'onsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mltsp import cfg\n",
    "from mltsp import featurize\n",
    "\n",
    "cfg.DEFAULT_MAX_TIME = 23.6\n",
    "fset_mltsp = featurize.featurize_time_series(None, m_list, None, \n",
    "                                             cfg.features_list_science,\n",
    "                                             classes)\n",
    "\n",
    "is_invalid = lambda x: np.any(np.isnan(x)) or np.any(np.abs(x) > 1e32)\n",
    "for feature in fset_mltsp.data_vars:\n",
    "    if is_invalid(fset_mltsp[feature].values):\n",
    "        fset_mltsp = fset_mltsp.drop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import scipy.stats\n",
    "from mltsp import featurize\n",
    "\n",
    "# Perform DWT and compute 5 standard features listed by Guo et al. (2012)\n",
    "# for each of 5 frequency bands\n",
    "n_channels = 5\n",
    "dwt_list = [pywt.wavedec(m, pywt.Wavelet('db1'), level=n_channels-1) for m in m_list]\n",
    "guo_dask = {\n",
    "    'mean': (np.mean, 'm'),\n",
    "    'std': (np.std, 'm'),\n",
    "    'mean2': (lambda x: np.mean(x ** 2), 'm'),\n",
    "    'abs_diffs': (lambda x: np.sum(np.abs(np.diff(x))), 'm'),\n",
    "    'skew': (scipy.stats.skew, 'm')\n",
    "}\n",
    "fset_guo = featurize.featurize_time_series(None, dwt_list, None, guo_dask.keys(),\n",
    "                                           classes, custom_functions=guo_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pyeeg\n",
    "from mltsp import featurize\n",
    "\n",
    "n_channels = 5\n",
    "dwt_list = [pywt.wavedec(m, pywt.Wavelet('db6'), level=n_channels-1) for m in m_list]\n",
    "pyeeg_dask = {\n",
    "    'ap_entropy': (lambda x: pyeeg.ap_entropy(x, M=2, R=0.15*np.std(x)), 'm'),\n",
    "#    'lyapunov': (lambda x: pyeeg.LLE(x, 2, 4, 1, 1), 'm')\n",
    "}\n",
    "fset_ocak = featurize.featurize_time_series(None, dwt_list, None, pyeeg_dask.keys(),\n",
    "                                            classes, custom_functions=pyeeg_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model_predictions() got an unexpected keyword argument 'return_probs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-06b779157ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmltsp_train_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmltsp_test_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_train_test_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mltsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfset_mltsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mguo_train_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguo_test_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_train_test_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_guo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfset_guo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mocak_train_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mocak_test_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_train_test_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ocak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfset_ocak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-06b779157ef8>\u001b[0m in \u001b[0;36mcv_train_test_errors\u001b[0;34m(model, fset, classes, cv_inds)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbuild_model_from_featureset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         train_errors[i] = np.mean(model_predictions(fset.isel(name=train), model, \n\u001b[0;32m---> 15\u001b[0;31m                                                     return_probs=False) != classes[train])\n\u001b[0m\u001b[1;32m     16\u001b[0m         test_errors[i] = np.mean(model_predictions(fset.isel(name=test), model,\n\u001b[1;32m     17\u001b[0m                                                    return_probs=False) != classes[test])\n",
      "\u001b[0;31mTypeError\u001b[0m: model_predictions() got an unexpected keyword argument 'return_probs'"
     ]
    }
   ],
   "source": [
    "from mltsp.build_model import build_model_from_featureset\n",
    "from mltsp.predict import model_predictions\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "def cv_train_test_errors(model, fset, classes, cv_inds):\n",
    "    train_errors = np.zeros(len(cv))\n",
    "    test_errors = np.zeros(len(cv))\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        build_model_from_featureset(fset.isel(name=train), model)\n",
    "        train_errors[i] = np.mean(model_predictions(fset.isel(name=train), model, \n",
    "                                                    return_probs=False) != classes[train])\n",
    "        test_errors[i] = np.mean(model_predictions(fset.isel(name=test), model,\n",
    "                                                   return_probs=False) != classes[test])\n",
    "    return train_errors, test_errors\n",
    "\n",
    "\n",
    "model_mltsp = RandomForestClassifier(n_estimators=1000, max_features='auto', random_state=0)\n",
    "model_guo = KNeighborsClassifier(n_neighbors=3)\n",
    "model_ocak = MLPClassifier(hidden_layer_sizes=(5,), max_iter=int(1e4), activation='tanh', alpha=1e-5)\n",
    "    \n",
    "cv = StratifiedKFold(classes, n_folds=2, random_state=0)\n",
    "mltsp_train_errors, mltsp_test_errors = cv_train_test_errors(model_mltsp, fset_mltsp, classes, cv)\n",
    "guo_train_errors, guo_test_errors = cv_train_test_errors(model_guo, fset_guo, classes, cv)\n",
    "ocak_train_errors, ocak_test_errors = cv_train_test_errors(model_ocak, fset_ocak, classes, cv)\n",
    "print(\"Built-in MLTSP features: average training error={:.2%}, average test error={:.2%}\".format(np.mean(mltsp_train_errors), np.mean(mltsp_test_errors)))\n",
    "print(\"Guo et al. features: average training error={:.2%}, average test error={:.2%}\".format(np.mean(guo_train_errors), np.mean(guo_test_errors)))\n",
    "print(\"App. entropy features: average training error={:.2%}, average test error={:.2%}\".format(np.mean(ocak_train_errors), np.mean(ocak_test_errors)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
